{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2f4ac-f9ce-43da-83fc-90aeb30f0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from donut import DonutModel\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "#Next, we need to extract the labels and parse the image names from the JSON file exported from UBIAI. We put the path of the labeled dataset and the processed folder (replace with your own path).\n",
    "\n",
    "\n",
    "\n",
    "ubiai_data_folder = \"/content/drive/MyDrive/Colab Notebooks/UBIAI_dataset\"\n",
    "ubiai_ocr_results = \"/content/drive/MyDrive/Colab Notebooks/UBIAI_dataset/ocr.json\"\n",
    "processed_dataset_folder = \"/content/drive/MyDrive/Colab Notebooks/UBIAI_dataset/processed_dataset\"\n",
    "with open(ubiai_ocr_results) as f:  data = json.load(f)#Extract labels from the JSON file\n",
    "all_labels = list()\n",
    "for j in data:\n",
    "  all_labels += list(j['annotation'][cc]['label'] for cc in range(len(j['annotation'])))all_labels = set(all_labels)\n",
    "all_labels#Setup image path\n",
    "images_metadata = list()\n",
    "images_path = list()for obs in data:ground_truth = dict()\n",
    "  for ann in obs['annotation']:\n",
    "    if ann['label'].strip() in ['SELLER', 'DATE', 'TTC', 'INVOICE_NUMBERS', 'TVA']:\n",
    "      ground_truth[ann['label'].strip()] = ann['text'].strip()try:\n",
    "    ground_truth = {key : ground_truth[key] for key in ['SELLER', 'DATE', 'TTC', 'INVOICE_NUMBERS', 'TVA']}\n",
    "  except:\n",
    "    continue\n",
    "images_metadata.append({\"gt_parse\": ground_truth})\n",
    "images_path.append(obs['images'][0]['name'].replace(':',''))dataset_len = len(images_metadata)\n",
    "\n",
    "We split the data into training, test and validation set. To do so, simply create three folders train, test and validation. Within each folder create an empty metadata.jsonl file and run the script below:\n",
    "\n",
    "for i, gt_parse in enumerate(images_metadata):\n",
    "  # train\n",
    "  if i < round(dataset_len*0.8) :\n",
    "    with open(processed_dataset_folder+\"/train/metadata.jsonl\", 'a') as f:\n",
    "      line = {\"file_name\": images_path[i], \"ground_truth\": json.dumps(gt_parse, ensure_ascii=False)}\n",
    "      f.write(json.dumps(line, ensure_ascii=False) + \"\n",
    "\")\n",
    "      shutil.copyfile(ubiai_data_folder + '/' + images_path[i], processed_dataset_folder + \"/train/\" + images_path[i])\n",
    "      if images_path[i] == \"050320sasdoodahfev20_2021-09-24_0722.txt_image_0.jpg\":\n",
    "        print('train')\n",
    "# test\n",
    "if round(dataset_len*0.8) <= i < round(dataset_len*0.8) + round(dataset_len*0.1):\n",
    "with open(processed_dataset_folder+\"/test/metadata.jsonl\", 'a') as f:\n",
    "line = {\"file_name\": images_path[i], \"ground_truth\": json.dumps(gt_parse, ensure_ascii=False)}\n",
    "f.write(json.dumps(line, ensure_ascii=False) + \" \")\n",
    "shutil.copyfile(ubiai_data_folder + '/' + images_path[i], processed_dataset_folder + \"/test/\" + images_path[i])\n",
    "if images_path[i] == \"050320sasdoodahfev20_2021-09-24_0722.txt_image_0.jpg\":\n",
    "print('test')# validation\n",
    "if round(dataset_len*0.8) + round(dataset_len*0.1) <= i < dataset_len:\n",
    "with open(processed_dataset_folder+\"/validation/metadata.jsonl\", 'a') as f:\n",
    "line = {\"file_name\": images_path[i], \"ground_truth\": json.dumps(gt_parse, ensure_ascii=False)}\n",
    "f.write(json.dumps(line, ensure_ascii=False) + \" \")\n",
    "shutil.copyfile(ubiai_data_folder + '/' + images_path[i], processed_dataset_folder + \"/validation/\" + images_path[i])\n",
    "\n",
    "The script will convert our original annotations into JSON format containing the image path and the ground truth:\n",
    "\n",
    "{\"file_name\": \"156260522812_2021-10-26_195802.2.txt_image_0.jpg\", \"ground_truth\": \"{\"gt_parse\": {\"SELLER\": \"TJF\", \"DATE\": \"création-09/05/2019\", \"TTC\": \"73,50 €\", \"INVOICE_NUMBERS\": \"N° 2019/068\", \"TVA\": \"12,25 €\"}}\"}{\"file_name\": \"156275474651_2021-10-26_195807.3.txt_image_0.jpg\", \"ground_truth\": \"{\"gt_parse\": {\"SELLER\": \"SAS CALIFRAIS\", \"DATE\": \"20/05/2019\", \"TTC\": \"108.62\", \"INVOICE_NUMBERS\": \"7133\", \"TVA\": \"5.66\"}}\"}\n",
    "Next, go to “/content/donut/config” folder, create a new file called “train.yaml” and copy the following config content (make sure to replace the dataset path by your own path):\n",
    "\n",
    "result_path: \"/content/drive/MyDrive/Colab Notebooks/UBIAI_dataset/processed_dataset/result\"\n",
    "pretrained_model_name_or_path: \"naver-clova-ix/donut-base\" # loading a pre-trained model (from moldehub or path)\n",
    "dataset_name_or_paths: [\"/content/drive/MyDrive/Colab Notebooks/UBIAI_dataset/processed_dataset\"] # loading datasets (from moldehub or path)\n",
    "sort_json_key: False # cord dataset is preprocessed, and publicly available at https://huggingface.co/datasets/naver-clova-ix/cord-v2\n",
    "train_batch_sizes: [1]\n",
    "val_batch_sizes: [1]\n",
    "input_size: [1280, 960] # when the input resolution differs from the pre-training setting, some weights will be newly initialized (but the model training would be okay)\n",
    "max_length: 768\n",
    "align_long_axis: False\n",
    "num_nodes: 1\n",
    "seed: 2022\n",
    "lr: 3e-5\n",
    "warmup_steps: 300 # 800/8*30/10, 10%\n",
    "num_training_samples_per_epoch: 800\n",
    "max_epochs: 50\n",
    "max_steps: -1\n",
    "num_workers: 8\n",
    "val_check_interval: 1.0\n",
    "check_val_every_n_epoch: 3\n",
    "gradient_clip_val: 1.0\n",
    "verbose: True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
